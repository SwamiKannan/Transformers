{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Sentiment Analysis </center>\n",
    "We seek to assess the accuracy of classification performance of a well tuned base BERT Transformer with Tensorflow.<br> We will be using the [Rotten Tomatoes movie reviews dataset](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data) for the analysis <br>.\n",
    "This excercise is performed across three phases:\n",
    "<ol>\n",
    "    <li> Data Transformation - Data Loading + EDA + Tokenization </li>\n",
    "    <li> Model Building and Training </li>\n",
    "    <li> Prediction </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Model Building and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert=TFAutoModel.from_pretrained('bert-base-cased') #creating a BERT layer object and updating the weights from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer=tf.keras.layers.Input(shape=(512,),name='ids',dtype='int32' )\n",
    "mask_layer=tf.keras.layers.Input(shape=(512,),name='masks',dtype='int32')\n",
    "embedding=bert.bert(input_layer, mask_layer)[1]\n",
    "dense1=tf.keras.layers.Dense(512, activation='relu')(embedding)\n",
    "dense2=tf.keras.layers.Dense(64, activation='relu')(dense1)\n",
    "dense3=tf.keras.layers.Dense(5, activation='softmax',name='outputs')(dense2)\n",
    "\n",
    "model=tf.keras.Model(inputs=(input_layer, mask_layer),outputs=dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ids (InputLayer)                [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masks (InputLayer)              [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   ids[0][0]                        \n",
      "                                                                 masks[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          393728      bert[1][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           32832       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            325         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 108,737,157\n",
      "Trainable params: 426,885\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We need to ensure that ids, masks, and the bert layer weights are not influenced by the training process and only the Dense layers are trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ids (InputLayer)                [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masks (InputLayer)              [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   ids[0][0]                        \n",
      "                                                                 masks[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          393728      bert[1][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           32832       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            325         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 108,737,157\n",
      "Trainable params: 426,885\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we see that the number of trainable params has decreased from 86,959,877 to 1,314,821 (98.5% decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizers=tf.keras.optimizers.Adam(learning_rate=5e-5, decay=1e-6)\n",
    "accuracies=tf.keras.metrics.CategoricalCrossentropy('accuracies')\n",
    "\n",
    "model.compile(optimizer=optimizers,loss=losses,metrics=[accuracies])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_spec=({'ids': tf.TensorSpec(shape=(32, 512), dtype=tf.int32, name=None), 'masks': tf.TensorSpec(shape=(32, 512), dtype=tf.int32, name=None)}, tf.TensorSpec(shape=(32, 5), dtype=tf.float64, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=tf.data.experimental.load('train',element_spec=elem_spec)\n",
    "validset=tf.data.experimental.load('validate', element_spec=elem_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ({ids: (32, 512), masks: (32, 512)}, (32, 5)), types: ({ids: tf.int32, masks: tf.int32}, tf.float64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.take(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 267/4389 [>.............................] - ETA: 65:10:30 - loss: 1.1811 - accuracies: 1.1811"
     ]
    }
   ],
   "source": [
    "hist=model.fit(trainset,validation_data=validset,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BERT_sentiment_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
